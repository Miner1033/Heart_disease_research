{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "avmyOd2rtgUU"
      },
      "outputs": [],
      "source": [
        "# Step 1: Import all necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Data preprocessing and feature engineering\n",
        "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Model selection and evaluation\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold, train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Models\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Imbalanced learning\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.pipeline import make_pipeline\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "# Hyperparameter optimization\n",
        "import optuna\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "print(\"All libraries imported successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Load and explore the data\n",
        "df = pd.read_csv('/kaggle/input/heart-disease-health-indicators-dataset/heart_disease_health_indicators_BRFSS2015.csv')\n",
        "\n",
        "print(\"Dataset shape:\", df.shape)\n",
        "print(\"\\nFirst few rows:\")\n",
        "print(df.head())\n",
        "\n",
        "print(\"\\nDataset info:\")\n",
        "print(df.info())\n",
        "\n",
        "print(\"\\nClass distribution:\")\n",
        "print(df['HeartDiseaseorAttack'].value_counts())\n",
        "print(\"Percentage of positive class: {:.2f}%\".format(df['HeartDiseaseorAttack'].mean() * 100))\n",
        "\n",
        "# Check basic statistics\n",
        "print(\"\\nBasic statistics:\")\n",
        "print(df.describe())"
      ],
      "metadata": {
        "id": "xOdI3iQOtmie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Data quality check and feature investigation\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"DATA QUALITY CHECK\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Check for missing values\n",
        "print(\"\\nMissing values:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Check the _RFHYPE5 column for potential leakage\n",
        "print(f\"\\n_RFHYPE5 value counts:\")\n",
        "print(df['_RFHYPE5'].value_counts())\n",
        "\n",
        "print(f\"\\nCross-tab of _RFHYPE5 vs HeartDiseaseorAttack:\")\n",
        "leakage_check = pd.crosstab(df['_RFHYPE5'], df['HeartDiseaseorAttack'], normalize='index')\n",
        "print(leakage_check)\n",
        "\n",
        "# Calculate correlation with target\n",
        "correlation_with_target = df.corr()['HeartDiseaseorAttack'].sort_values(ascending=False)\n",
        "print(f\"\\nTop 10 features correlated with target:\")\n",
        "print(correlation_with_target.head(10))\n",
        "\n",
        "# Based on the high correlation, we'll drop this column to avoid potential leakage\n",
        "print(\"\\nDropping _RFHYPE5 column to avoid potential data leakage...\")\n",
        "df = df.drop('_RFHYPE5', axis=1)\n",
        "print(f\"Dataset shape after dropping _RFHYPE5: {df.shape}\")"
      ],
      "metadata": {
        "id": "kGdQA9FbtptR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Advanced Feature Engineering\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"FEATURE ENGINEERING\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Create interaction features and risk scores\n",
        "def create_new_features(df):\n",
        "    df_copy = df.copy()\n",
        "\n",
        "    # Create interaction terms\n",
        "    df_copy['BMI_Age'] = df_copy['BMI'] * df_copy['Age']\n",
        "    df_copy['BP_Chol'] = df_copy['HighBP'] * df_copy['HighChol']\n",
        "    df_copy['Diabetes_Smoker'] = df_copy['Diabetes'] * df_copy['Smoker']\n",
        "    df_copy['Age_GenHlth'] = df_copy['Age'] * df_copy['GenHlth']\n",
        "\n",
        "    # Create comprehensive risk scores\n",
        "    df_copy['TotalRiskScore'] = (df_copy['HighBP'] + df_copy['HighChol'] +\n",
        "                                df_copy['Smoker'] + df_copy['Diabetes'] +\n",
        "                                df_copy['Stroke'] + df_copy['PhysActivity'])\n",
        "\n",
        "    df_copy['LifestyleRisk'] = (df_copy['Smoker'] + df_copy['HvyAlcoholConsump'] +\n",
        "                               (5 - df_copy['GenHlth']))  # Lower GenHlth = worse health\n",
        "\n",
        "    df_copy['MedicalHistoryScore'] = (df_copy['HighBP'] + df_copy['HighChol'] +\n",
        "                                     df_copy['Diabetes'] + df_copy['Stroke'])\n",
        "\n",
        "    # Create age groups\n",
        "    df_copy['AgeGroup'] = pd.cut(df_copy['Age'], bins=[0, 35, 50, 65, 80, 100],\n",
        "                                labels=[1, 2, 3, 4, 5])\n",
        "\n",
        "    # BMI categories\n",
        "    df_copy['BMICategory'] = pd.cut(df_copy['BMI'], bins=[0, 18.5, 25, 30, 100],\n",
        "                                   labels=[1, 2, 3, 4])\n",
        "\n",
        "    # Fill NaN values created by cutting\n",
        "    df_copy['AgeGroup'] = df_copy['AgeGroup'].cat.codes\n",
        "    df_copy['BMICategory'] = df_copy['BMICategory'].cat.codes\n",
        "\n",
        "    return df_copy\n",
        "\n",
        "df_enhanced = create_new_features(df)\n",
        "print(f\"Original features: {len(df.columns)}\")\n",
        "print(f\"After feature engineering: {len(df_enhanced.columns)}\")\n",
        "print(\"New features created: BMI_Age, BP_Chol, Diabetes_Smoker, Age_GenHlth, TotalRiskScore, LifestyleRisk, MedicalHistoryScore, AgeGroup, BMICategory\")\n",
        "\n",
        "# Show correlation of new features with target\n",
        "new_features_corr = df_enhanced.corr()['HeartDiseaseorAttack'].sort_values(ascending=False)\n",
        "print(f\"\\nTop 15 features correlated with target (including new features):\")\n",
        "print(new_features_corr.head(15))"
      ],
      "metadata": {
        "id": "jQmoAkDnttmZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Prepare final feature set and target\n",
        "X = df_enhanced.drop('HeartDiseaseorAttack', axis=1)\n",
        "y = df_enhanced['HeartDiseaseorAttack']\n",
        "\n",
        "print(f\"\\nFinal feature set shape: {X.shape}\")\n",
        "print(f\"Target distribution:\")\n",
        "print(y.value_counts())\n",
        "print(f\"Positive class percentage: {y.mean():.3f}\")\n",
        "\n",
        "# List all features\n",
        "print(f\"\\nAll features used for modeling:\")\n",
        "for i, col in enumerate(X.columns, 1):\n",
        "    print(f\"{i:2d}. {col}\")"
      ],
      "metadata": {
        "id": "3rredpPMtyLD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Define advanced Optuna objective function\n",
        "def objective(trial):\n",
        "    # Suggest model type\n",
        "    model_type = trial.suggest_categorical('model_type', ['xgb', 'lgbm', 'rf'])\n",
        "\n",
        "    if model_type == 'xgb':\n",
        "        params = {\n",
        "            'n_estimators': trial.suggest_int('n_estimators', 300, 2000),\n",
        "            'max_depth': trial.suggest_int('max_depth', 4, 12),\n",
        "            'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.3, log=True),\n",
        "            'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
        "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
        "            'reg_alpha': trial.suggest_float('reg_alpha', 1e-4, 10.0, log=True),\n",
        "            'reg_lambda': trial.suggest_float('reg_lambda', 1e-4, 10.0, log=True),\n",
        "            'gamma': trial.suggest_float('gamma', 0, 5),\n",
        "            'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
        "            'random_state': 42\n",
        "        }\n",
        "        model = XGBClassifier(**params, use_label_encoder=False, eval_metric='logloss')\n",
        "\n",
        "    elif model_type == 'lgbm':\n",
        "        params = {\n",
        "            'n_estimators': trial.suggest_int('n_estimators', 300, 2000),\n",
        "            'max_depth': trial.suggest_int('max_depth', 4, 12),\n",
        "            'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.3, log=True),\n",
        "            'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
        "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
        "            'reg_alpha': trial.suggest_float('reg_alpha', 1e-4, 10.0, log=True),\n",
        "            'reg_lambda': trial.suggest_float('reg_lambda', 1e-4, 10.0, log=True),\n",
        "            'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
        "            'random_state': 42\n",
        "        }\n",
        "        model = LGBMClassifier(**params)\n",
        "\n",
        "    else:  # Random Forest\n",
        "        params = {\n",
        "            'n_estimators': trial.suggest_int('n_estimators', 200, 1000),\n",
        "            'max_depth': trial.suggest_int('max_depth', 8, 20),\n",
        "            'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n",
        "            'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\n",
        "            'max_features': trial.suggest_float('max_features', 0.1, 1.0),\n",
        "            'bootstrap': trial.suggest_categorical('bootstrap', [True, False]),\n",
        "            'random_state': 42\n",
        "        }\n",
        "        model = RandomForestClassifier(**params)\n",
        "\n",
        "    # Create pipeline with SMOTE\n",
        "    pipeline = make_pipeline(\n",
        "        SMOTE(random_state=42),\n",
        "        model\n",
        "    )\n",
        "\n",
        "    # Use Stratified K-Fold Cross-Validation\n",
        "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    scores = cross_val_score(pipeline, X, y, cv=cv, scoring='accuracy', n_jobs=-1)\n",
        "\n",
        "    return scores.mean()\n",
        "\n",
        "print(\"Optuna objective function defined successfully!\")"
      ],
      "metadata": {
        "id": "yIiclel1tzCV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Run hyperparameter optimization\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"HYPERPARAMETER OPTIMIZATION\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "print(\"Starting Optuna optimization with 150 trials...\")\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=150, show_progress_bar=True)\n",
        "\n",
        "print('\\nBest trial:')\n",
        "trial = study.best_trial\n",
        "print(f'  Best Accuracy: {trial.value:.5f}')\n",
        "print(f'  Best Model Type: {trial.params[\"model_type\"]}')\n",
        "print(f'  Best Params:')\n",
        "for key, value in trial.params.items():\n",
        "    print(f'    {key}: {value}')\n",
        "\n",
        "# Plot optimization history\n",
        "plt.figure(figsize=(10, 6))\n",
        "optuna.visualization.plot_optimization_history(study)\n",
        "plt.title('Optuna Optimization History')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "G_rlXOTUt1J5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Ujd6umO3t3pw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 8: Train the best single model\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"TRAINING BEST SINGLE MODEL\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "best_params = trial.params.copy()\n",
        "model_type = best_params.pop('model_type')\n",
        "\n",
        "print(f\"Training best {model_type.upper()} model...\")\n",
        "\n",
        "if model_type == 'xgb':\n",
        "    best_model = XGBClassifier(**best_params, use_label_encoder=False, eval_metric='logloss')\n",
        "elif model_type == 'lgbm':\n",
        "    best_model = LGBMClassifier(**best_params)\n",
        "else:\n",
        "    best_model = RandomForestClassifier(**best_params)\n",
        "\n",
        "# Create pipeline with best model\n",
        "final_pipeline = make_pipeline(\n",
        "    SMOTE(random_state=42),\n",
        "    best_model\n",
        ")\n",
        "\n",
        "# Train on full data\n",
        "final_pipeline.fit(X, y)\n",
        "print(\"Best single model trained successfully!\")\n",
        "\n",
        "# Cross-validation score\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "cv_scores = cross_val_score(final_pipeline, X, y, cv=cv, scoring='accuracy', n_jobs=-1)\n",
        "print(f\"Cross-validation scores: {cv_scores}\")\n",
        "print(f\"Mean CV Accuracy: {cv_scores.mean():.5f} (+/- {cv_scores.std() * 2:.5f})\")"
      ],
      "metadata": {
        "id": "6AWEx-vwt4Dq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 9: Create an Ensemble Model (Stacking)\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"CREATING ENSEMBLE MODEL\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Define base models for stacking\n",
        "base_models = [\n",
        "    ('xgb', XGBClassifier(\n",
        "        n_estimators=1000,\n",
        "        max_depth=8,\n",
        "        learning_rate=0.1,\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.8,\n",
        "        random_state=42,\n",
        "        use_label_encoder=False,\n",
        "        eval_metric='logloss'\n",
        "    )),\n",
        "    ('lgbm', LGBMClassifier(\n",
        "        n_estimators=1000,\n",
        "        max_depth=8,\n",
        "        learning_rate=0.1,\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.8,\n",
        "        random_state=42\n",
        "    )),\n",
        "    ('rf', RandomForestClassifier(\n",
        "        n_estimators=500,\n",
        "        max_depth=15,\n",
        "        min_samples_split=10,\n",
        "        min_samples_leaf=4,\n",
        "        max_features=0.7,\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    ))\n",
        "]\n",
        "\n",
        "# Create stacking classifier\n",
        "stacking_model = StackingClassifier(\n",
        "    estimators=base_models,\n",
        "    final_estimator=LogisticRegression(C=0.1, random_state=42, max_iter=1000),\n",
        "    cv=5,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Create pipeline for stacking\n",
        "stacking_pipeline = make_pipeline(\n",
        "    SMOTE(random_state=42),\n",
        "    stacking_model\n",
        ")\n",
        "\n",
        "print(\"Training ensemble model...\")\n",
        "stacking_pipeline.fit(X, y)\n",
        "print(\"Ensemble model trained successfully!\")\n",
        "\n",
        "# Cross-validation score for ensemble\n",
        "cv_scores_ensemble = cross_val_score(stacking_pipeline, X, y, cv=cv, scoring='accuracy', n_jobs=-1)\n",
        "print(f\"Ensemble CV scores: {cv_scores_ensemble}\")\n",
        "print(f\"Ensemble Mean CV Accuracy: {cv_scores_ensemble.mean():.5f} (+/- {cv_scores_ensemble.std() * 2:.5f})\")"
      ],
      "metadata": {
        "id": "FpeKLCuOt7Wb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 10: Model Evaluation and Comparison\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"MODEL EVALUATION\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Split data for final evaluation\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(f\"Training set shape: {X_train.shape}\")\n",
        "print(f\"Test set shape: {X_test.shape}\")\n",
        "\n",
        "# Train both models on training set for fair comparison\n",
        "print(\"Training models on training set...\")\n",
        "final_pipeline.fit(X_train, y_train)\n",
        "stacking_pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "single_pred = final_pipeline.predict(X_test)\n",
        "ensemble_pred = stacking_pipeline.predict(X_test)\n",
        "\n",
        "# Calculate accuracies\n",
        "single_accuracy = accuracy_score(y_test, single_pred)\n",
        "ensemble_accuracy = accuracy_score(y_test, ensemble_pred)\n",
        "\n",
        "print(f\"\\nSingle Model Test Accuracy: {single_accuracy:.5f}\")\n",
        "print(f\"Ensemble Model Test Accuracy: {ensemble_accuracy:.5f}\")\n",
        "\n",
        "# Choose the best model\n",
        "if ensemble_accuracy >= single_accuracy:\n",
        "    best_final_model = stacking_pipeline\n",
        "    best_accuracy = ensemble_accuracy\n",
        "    model_name = \"Ensemble Stacking Model\"\n",
        "else:\n",
        "    best_final_model = final_pipeline\n",
        "    best_accuracy = single_accuracy\n",
        "    model_name = \"Single Best Model\"\n",
        "\n",
        "print(f\"\\nSelected {model_name} with accuracy: {best_accuracy:.5f}\")\n",
        "\n",
        "# Detailed classification report\n",
        "print(f\"\\nDetailed Classification Report for {model_name}:\")\n",
        "if model_name == \"Ensemble Stacking Model\":\n",
        "    y_pred = ensemble_pred\n",
        "else:\n",
        "    y_pred = single_pred\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title(f'Confusion Matrix - {model_name}')\n",
        "plt.ylabel('Actual')\n",
        "plt.xlabel('Predicted')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "s3s2OIsit_zA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 11: Feature Importance Analysis\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"FEATURE IMPORTANCE ANALYSIS\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "def get_feature_importance(model, feature_names):\n",
        "    \"\"\"Extract feature importance from different model types\"\"\"\n",
        "    if hasattr(model, 'feature_importances_'):\n",
        "        # For single tree-based models\n",
        "        return model.feature_importances_\n",
        "    elif hasattr(model, 'estimators_'):\n",
        "        # For stacking classifier - use the first base model\n",
        "        return model.estimators_[0].feature_importances_\n",
        "    elif hasattr(model, 'coef_'):\n",
        "        # For linear models\n",
        "        return np.abs(model.coef_[0])\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "# Get the actual model from the pipeline\n",
        "if model_name == \"Ensemble Stacking Model\":\n",
        "    actual_model = best_final_model.steps[-1][1]\n",
        "else:\n",
        "    actual_model = best_final_model.steps[-1][1]\n",
        "\n",
        "feature_importances = get_feature_importance(actual_model, X.columns)\n",
        "\n",
        "if feature_importances is not None:\n",
        "    feature_importance_df = pd.DataFrame({\n",
        "        'feature': X.columns,\n",
        "        'importance': feature_importances\n",
        "    }).sort_values('importance', ascending=False)\n",
        "\n",
        "    print(\"\\nTop 15 Most Important Features:\")\n",
        "    print(feature_importance_df.head(15))\n",
        "\n",
        "    # Plot feature importance\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    sns.barplot(data=feature_importance_df.head(15), x='importance', y='feature')\n",
        "    plt.title('Top 15 Feature Importances')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Feature importance not available for this model type.\")"
      ],
      "metadata": {
        "id": "hqEmSeO-uAuP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 12: Final Model Training and Saving\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"FINAL MODEL TRAINING AND SAVING\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Retrain the best model on the full dataset\n",
        "print(\"Training final model on full dataset...\")\n",
        "best_final_model.fit(X, y)\n",
        "\n",
        "# Final cross-validation\n",
        "cv_scores_final = cross_val_score(best_final_model, X, y, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "print(f\"Final Cross-Validation Scores: {cv_scores_final}\")\n",
        "print(f\"Final Mean CV Accuracy: {cv_scores_final.mean():.5f} (+/- {cv_scores_final.std() * 2:.5f})\")\n",
        "\n",
        "# Save the model\n",
        "import joblib\n",
        "\n",
        "model_filename = 'heart_disease_best_model.pkl'\n",
        "feature_filename = 'feature_names.pkl'\n",
        "\n",
        "joblib.dump(best_final_model, model_filename)\n",
        "joblib.dump(list(X.columns), feature_filename)\n",
        "\n",
        "print(f\"\\nModel saved as: {model_filename}\")\n",
        "print(f\"Feature names saved as: {feature_filename}\")\n",
        "\n",
        "# Final summary\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"FINAL SUMMARY\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Best Model: {model_name}\")\n",
        "print(f\"Final CV Accuracy: {cv_scores_final.mean():.5f}\")\n",
        "print(f\"Number of Features: {X.shape[1]}\")\n",
        "print(f\"Dataset Size: {X.shape[0]} samples\")\n",
        "print(f\"Positive Class Ratio: {y.mean():.3f}\")"
      ],
      "metadata": {
        "id": "o1ksYejvuD2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 13: Reality Check\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"REALITY CHECK - IMPORTANT NOTES\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\"\"\n",
        "⚠️ ACHIEVING 99.5% ACCURACY - REALITY CHECK:\n",
        "\n",
        "1. MEDICAL DATA CHALLENGES:\n",
        "   - Real-world medical data rarely achieves >99% accuracy\n",
        "   - High accuracy might indicate data leakage or overfitting\n",
        "   - Focus on robust cross-validation scores, not just test accuracy\n",
        "\n",
        "2. VERIFICATION STEPS:\n",
        "   - Ensure no target leakage in features\n",
        "   - Check cross-validation consistency\n",
        "   - Validate on completely independent dataset if possible\n",
        "\n",
        "3. ALTERNATIVE METRICS:\n",
        "   - For medical data, RECALL (sensitivity) is often more important than accuracy\n",
        "   - Precision and F1-score provide better picture of model performance\n",
        "   - Consider ROC-AUC for binary classification\n",
        "\n",
        "4. NEXT STEPS FOR IMPROVEMENT:\n",
        "   - Try neural networks with careful regularization\n",
        "   - Experiment with different feature combinations\n",
        "   - Consider feature selection to remove noise\n",
        "   - Try more sophisticated ensemble methods\n",
        "\n",
        "Current performance is excellent if CV accuracy > 90%!\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "JZ-NZDwvuF77"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}